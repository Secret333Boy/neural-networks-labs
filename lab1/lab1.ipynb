{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59597, 784)\n",
      "(59597, 1)\n",
      "(10403, 784)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./dataset/train.csv\")\n",
    "test = pd.read_csv(\"./dataset/test.csv\")\n",
    "\n",
    "x_train = train.drop(columns=[\"Id\", \"label\"]).to_numpy()\n",
    "y_train = train[\"label\"].to_numpy()[:, np.newaxis]\n",
    "\n",
    "x_test = test.drop(columns=[\"Id\"]).to_numpy()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from tmp/mnist/tuner0.json\n",
      "Найкращі параметри:\n",
      "\n",
      "{'layers': 6, 'learning_rate': 3.796301284993931e-05, 'units_0': 416, 'dropout_rate_0': 0.05, 'units_1': 1792, 'dropout_rate_1': 0.05, 'units_2': 1056, 'dropout_rate_2': 0.30000000000000004, 'units_3': 1600, 'dropout_rate_3': 0.05, 'units_4': 1280, 'dropout_rate_4': 0.2, 'units_5': 736, 'dropout_rate_5': 0.15000000000000002, 'units_6': 160, 'dropout_rate_6': 0.4, 'units_7': 1632, 'dropout_rate_7': 0.45, 'units_8': 1568, 'dropout_rate_8': 0.15000000000000002, 'units_9': 1888, 'dropout_rate_9': 0.0, 'units_10': 2048, 'dropout_rate_10': 0.0, 'units_11': 1216, 'dropout_rate_11': 0.4, 'units_12': 1472, 'dropout_rate_12': 0.0, 'units_13': 384, 'dropout_rate_13': 0.30000000000000004, 'units_14': 1344, 'dropout_rate_14': 0.2, 'units_15': 1952, 'dropout_rate_15': 0.30000000000000004, 'units_16': 1632, 'dropout_rate_16': 0.2, 'units_17': 1984, 'dropout_rate_17': 0.35000000000000003, 'units_18': 1376, 'dropout_rate_18': 0.1, 'units_19': 896, 'dropout_rate_19': 0.4, 'tuner/epochs': 10, 'tuner/initial_epoch': 4, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '0013'}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    hp_layers = hp.Int('layers', min_value=6, max_value=20, step=2)\n",
    "    hp_learning_rate = hp.Float(\n",
    "      'learning_rate',\n",
    "      min_value=1e-6,\n",
    "      max_value=1e-2,\n",
    "      sampling='LOG',\n",
    "      default=1e-3\n",
    "    )\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Input(shape=(784,)))\n",
    "    \n",
    "    for i in range(hp_layers):\n",
    "      model.add(Dense(hp.Int(f'units_{i}', min_value=32, max_value=2048, step=32), activation='relu'))\n",
    "      model.add(Dropout(rate=hp.Float(\n",
    "        f'dropout_rate_{i}',\n",
    "        min_value=0.0,\n",
    "        max_value=0.5,\n",
    "        default=0.25,\n",
    "        step=0.05,\n",
    "      )))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "                    loss=SparseCategoricalCrossentropy(),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='tmp',\n",
    "                     project_name='mnist')\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner.search(x_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"Найкращі параметри:\\n\")\n",
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.6192 - loss: 3.4492 - val_accuracy: 0.9201 - val_loss: 0.2799\n",
      "Epoch 2/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8788 - loss: 0.4240 - val_accuracy: 0.9396 - val_loss: 0.1999\n",
      "Epoch 3/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9171 - loss: 0.2774 - val_accuracy: 0.9522 - val_loss: 0.1572\n",
      "Epoch 4/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9401 - loss: 0.2010 - val_accuracy: 0.9595 - val_loss: 0.1362\n",
      "Epoch 5/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9529 - loss: 0.1521 - val_accuracy: 0.9648 - val_loss: 0.1149\n",
      "Epoch 6/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9604 - loss: 0.1250 - val_accuracy: 0.9652 - val_loss: 0.1247\n",
      "Epoch 7/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9694 - loss: 0.0959 - val_accuracy: 0.9669 - val_loss: 0.1144\n",
      "Epoch 8/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.0745 - val_accuracy: 0.9673 - val_loss: 0.1207\n",
      "Epoch 9/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9795 - loss: 0.0599 - val_accuracy: 0.9718 - val_loss: 0.1138\n",
      "Epoch 10/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9847 - loss: 0.0481 - val_accuracy: 0.9725 - val_loss: 0.1092\n",
      "Epoch 11/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.0442 - val_accuracy: 0.9719 - val_loss: 0.1214\n",
      "Epoch 12/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0351 - val_accuracy: 0.9721 - val_loss: 0.1264\n",
      "Epoch 13/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0280 - val_accuracy: 0.9735 - val_loss: 0.1206\n",
      "Epoch 14/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0276 - val_accuracy: 0.9735 - val_loss: 0.1292\n",
      "Epoch 15/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.0231 - val_accuracy: 0.9739 - val_loss: 0.1310\n",
      "Epoch 16/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0242 - val_accuracy: 0.9743 - val_loss: 0.1299\n",
      "Epoch 17/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0186 - val_accuracy: 0.9717 - val_loss: 0.1571\n",
      "Epoch 18/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9940 - loss: 0.0218 - val_accuracy: 0.9712 - val_loss: 0.1660\n",
      "Epoch 19/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0190 - val_accuracy: 0.9727 - val_loss: 0.1533\n",
      "Epoch 20/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0166 - val_accuracy: 0.9742 - val_loss: 0.1642\n",
      "Epoch 21/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0197 - val_accuracy: 0.9739 - val_loss: 0.1558\n",
      "Epoch 22/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0155 - val_accuracy: 0.9738 - val_loss: 0.1655\n",
      "Epoch 23/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0155 - val_accuracy: 0.9740 - val_loss: 0.1510\n",
      "Epoch 24/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0117 - val_accuracy: 0.9730 - val_loss: 0.1826\n",
      "Epoch 25/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0170 - val_accuracy: 0.9747 - val_loss: 0.1626\n",
      "Epoch 26/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0104 - val_accuracy: 0.9748 - val_loss: 0.1411\n",
      "Epoch 27/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0097 - val_accuracy: 0.9758 - val_loss: 0.1506\n",
      "Epoch 28/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.0100 - val_accuracy: 0.9761 - val_loss: 0.1520\n",
      "Epoch 29/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0092 - val_accuracy: 0.9720 - val_loss: 0.1940\n",
      "Epoch 30/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9960 - loss: 0.0143 - val_accuracy: 0.9758 - val_loss: 0.1502\n",
      "Epoch 31/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0067 - val_accuracy: 0.9751 - val_loss: 0.1693\n",
      "Epoch 32/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0131 - val_accuracy: 0.9742 - val_loss: 0.1674\n",
      "Epoch 33/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0111 - val_accuracy: 0.9749 - val_loss: 0.1815\n",
      "Epoch 34/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0083 - val_accuracy: 0.9783 - val_loss: 0.1794\n",
      "Epoch 35/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9975 - loss: 0.0084 - val_accuracy: 0.9765 - val_loss: 0.1912\n",
      "Epoch 36/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0107 - val_accuracy: 0.9749 - val_loss: 0.2101\n",
      "Epoch 37/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9975 - loss: 0.0104 - val_accuracy: 0.9746 - val_loss: 0.1942\n",
      "Epoch 38/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0062 - val_accuracy: 0.9765 - val_loss: 0.1875\n",
      "Epoch 39/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0080 - val_accuracy: 0.9762 - val_loss: 0.2102\n",
      "Epoch 40/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0122 - val_accuracy: 0.9775 - val_loss: 0.1728\n",
      "Epoch 41/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0074 - val_accuracy: 0.9782 - val_loss: 0.1640\n",
      "Epoch 42/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.9779 - val_loss: 0.1646\n",
      "Epoch 43/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0081 - val_accuracy: 0.9769 - val_loss: 0.1997\n",
      "Epoch 44/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0072 - val_accuracy: 0.9784 - val_loss: 0.1607\n",
      "Epoch 45/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 0.9764 - val_loss: 0.2271\n",
      "Epoch 46/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0078 - val_accuracy: 0.9762 - val_loss: 0.2072\n",
      "Epoch 47/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0069 - val_accuracy: 0.9752 - val_loss: 0.2243\n",
      "Epoch 48/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0073 - val_accuracy: 0.9748 - val_loss: 0.2167\n",
      "Epoch 49/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0064 - val_accuracy: 0.9788 - val_loss: 0.1574\n",
      "Epoch 50/50\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.9773 - val_loss: 0.1896\n",
      "Best epoch: 49\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(x_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.6196 - loss: 3.4923 - val_accuracy: 0.9206 - val_loss: 0.2586\n",
      "Epoch 2/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8726 - loss: 0.4355 - val_accuracy: 0.9413 - val_loss: 0.1964\n",
      "Epoch 3/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9184 - loss: 0.2699 - val_accuracy: 0.9523 - val_loss: 0.1557\n",
      "Epoch 4/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9388 - loss: 0.2014 - val_accuracy: 0.9579 - val_loss: 0.1340\n",
      "Epoch 5/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9497 - loss: 0.1612 - val_accuracy: 0.9638 - val_loss: 0.1180\n",
      "Epoch 6/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9601 - loss: 0.1318 - val_accuracy: 0.9666 - val_loss: 0.1151\n",
      "Epoch 7/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9686 - loss: 0.1015 - val_accuracy: 0.9693 - val_loss: 0.1094\n",
      "Epoch 8/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.0782 - val_accuracy: 0.9711 - val_loss: 0.1082\n",
      "Epoch 9/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9792 - loss: 0.0648 - val_accuracy: 0.9746 - val_loss: 0.1033\n",
      "Epoch 10/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9828 - loss: 0.0543 - val_accuracy: 0.9721 - val_loss: 0.1122\n",
      "Epoch 11/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9860 - loss: 0.0433 - val_accuracy: 0.9747 - val_loss: 0.1095\n",
      "Epoch 12/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0343 - val_accuracy: 0.9741 - val_loss: 0.1087\n",
      "Epoch 13/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9898 - loss: 0.0315 - val_accuracy: 0.9743 - val_loss: 0.1239\n",
      "Epoch 14/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9890 - loss: 0.0323 - val_accuracy: 0.9752 - val_loss: 0.1251\n",
      "Epoch 15/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0248 - val_accuracy: 0.9750 - val_loss: 0.1193\n",
      "Epoch 16/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.0224 - val_accuracy: 0.9752 - val_loss: 0.1265\n",
      "Epoch 17/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9927 - loss: 0.0220 - val_accuracy: 0.9778 - val_loss: 0.1242\n",
      "Epoch 18/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9935 - loss: 0.0207 - val_accuracy: 0.9766 - val_loss: 0.1299\n",
      "Epoch 19/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0197 - val_accuracy: 0.9754 - val_loss: 0.1359\n",
      "Epoch 20/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0171 - val_accuracy: 0.9763 - val_loss: 0.1359\n",
      "Epoch 21/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0155 - val_accuracy: 0.9763 - val_loss: 0.1386\n",
      "Epoch 22/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0158 - val_accuracy: 0.9747 - val_loss: 0.1530\n",
      "Epoch 23/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0132 - val_accuracy: 0.9715 - val_loss: 0.1787\n",
      "Epoch 24/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9954 - loss: 0.0159 - val_accuracy: 0.9760 - val_loss: 0.1476\n",
      "Epoch 25/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0161 - val_accuracy: 0.9763 - val_loss: 0.1595\n",
      "Epoch 26/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0120 - val_accuracy: 0.9774 - val_loss: 0.1491\n",
      "Epoch 27/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9961 - loss: 0.0135 - val_accuracy: 0.9763 - val_loss: 0.1450\n",
      "Epoch 28/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.0117 - val_accuracy: 0.9767 - val_loss: 0.1540\n",
      "Epoch 29/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9957 - loss: 0.0141 - val_accuracy: 0.9750 - val_loss: 0.1861\n",
      "Epoch 30/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0120 - val_accuracy: 0.9778 - val_loss: 0.1499\n",
      "Epoch 31/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0069 - val_accuracy: 0.9765 - val_loss: 0.1601\n",
      "Epoch 32/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0117 - val_accuracy: 0.9791 - val_loss: 0.1642\n",
      "Epoch 33/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0095 - val_accuracy: 0.9766 - val_loss: 0.1616\n",
      "Epoch 34/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0079 - val_accuracy: 0.9783 - val_loss: 0.1401\n",
      "Epoch 35/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0094 - val_accuracy: 0.9769 - val_loss: 0.1524\n",
      "Epoch 36/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9976 - loss: 0.0087 - val_accuracy: 0.9764 - val_loss: 0.1517\n",
      "Epoch 37/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9975 - loss: 0.0086 - val_accuracy: 0.9796 - val_loss: 0.1422\n",
      "Epoch 38/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0079 - val_accuracy: 0.9778 - val_loss: 0.1567\n",
      "Epoch 39/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9977 - loss: 0.0076 - val_accuracy: 0.9780 - val_loss: 0.1747\n",
      "Epoch 40/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0073 - val_accuracy: 0.9782 - val_loss: 0.1651\n",
      "Epoch 41/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0075 - val_accuracy: 0.9789 - val_loss: 0.1754\n",
      "Epoch 42/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0082 - val_accuracy: 0.9784 - val_loss: 0.1635\n",
      "Epoch 43/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0049 - val_accuracy: 0.9768 - val_loss: 0.1775\n",
      "Epoch 44/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0096 - val_accuracy: 0.9780 - val_loss: 0.1677\n",
      "Epoch 45/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0054 - val_accuracy: 0.9786 - val_loss: 0.1500\n",
      "Epoch 46/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0076 - val_accuracy: 0.9768 - val_loss: 0.1929\n",
      "Epoch 47/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0060 - val_accuracy: 0.9727 - val_loss: 0.2487\n",
      "Epoch 48/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9977 - loss: 0.0097 - val_accuracy: 0.9791 - val_loss: 0.1707\n",
      "Epoch 49/49\n",
      "\u001b[1m1490/1490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0042 - val_accuracy: 0.9796 - val_loss: 0.1762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7faee07fc640>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "hypermodel.fit(x_train, y_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m324/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 09:49:26.396485: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_25', 304 bytes spill stores, 384 bytes spill loads\n",
      "\n",
      "2025-03-08 09:49:26.773453: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 288 bytes spill stores, 356 bytes spill loads\n",
      "\n",
      "2025-03-08 09:49:27.041610: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2025-03-08 09:49:27.333558: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_46', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2025-03-08 09:49:27.466016: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_46', 272 bytes spill stores, 320 bytes spill loads\n",
      "\n",
      "2025-03-08 09:49:27.484408: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_60', 136 bytes spill stores, 136 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m326/326\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 3, 4, ..., 9, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = hypermodel.predict(x_test)\n",
    "\n",
    "results = np.array(predictions).argmax(axis=1)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = test[\"Id\"].to_numpy()\n",
    "\n",
    "result_df = pd.DataFrame({\"Id\": ids, \"label\": results}, columns=[\"Id\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"./output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
